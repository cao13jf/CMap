{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837275b3",
   "metadata": {},
   "source": [
    "# Running Segmentation Notebook\n",
    "\n",
    "## We have finished the segmentation training and get the trained model model_epoch_50.pth . We are generating the segmented cell membrane and cell morphological objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f652a69",
   "metadata": {},
   "source": [
    "### Place your runing augments at ./experiment/TRAIN_TEST.yaml or change it at the Paramenters configuration section "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb421bf8",
   "metadata": {},
   "source": [
    "```\n",
    "# =================================\n",
    "# Parameters for prediction (Paras for training will be preserved)\n",
    "# =================================\n",
    "get_memb_bin: True\n",
    "show_snap: False\n",
    "get_cell: True\n",
    "\n",
    "\n",
    "test_data_dir: ./dataset/run\n",
    "test_embryos: [200109plc1p1,200113plc1p2]\n",
    "test_max_times: [180,187]\n",
    "\n",
    "test_transforms: # for testing\n",
    "  Compose([\n",
    "    Resize((256,352,224)),\n",
    "    NumpyType((np.float32, np.float32)),\n",
    "    ])\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf27020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import argparse\n",
    "import setproctitle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import models \n",
    "from utils import ParserUse\n",
    "from utils.show_train import Visualizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca48799",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True # https://zhuanlan.zhihu.com/p/73711222 to accelerate the network\n",
    "## parse arguments\n",
    "args = ParserUse('TRAIN_TEST', log='run')\n",
    "# CHANGE Your training parameters here\n",
    "args.mode=2\n",
    "args.gpu='0'\n",
    "args.ckpts='./ckpts'\n",
    "args.suffix='*.pkl'\n",
    "args.save_format='nii'\n",
    "args.resume=r'./ckpts/CMap_model_epoch_50.pth'\n",
    "is_scoring = False\n",
    "\n",
    "visualizer = None\n",
    "if args.show_snap:\n",
    "    visualizer = Visualizer(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39f20b",
   "metadata": {},
   "source": [
    "## Start run the prediction on your computer with gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "163feb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setproctitle.setproctitle(args.cfg)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "assert torch.cuda.is_available(), \"GPU is needed for prediction\"\n",
    "\n",
    "# =============================================================\n",
    "#  set seeds for randomlization in TRAIN_TEST.yaml\n",
    "# =============================================================\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b389e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 17:13:32,229 Note: NumExpr detected 48 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-07-18 17:13:32,230 NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Loading parameters ./ckpts/CMap_model_epoch_50.pth====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting binary membrane:: 100%|█████████████████████████████| 367/367 [16:26<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "from data import datasets\n",
    "from utils.prediction_utils import validate\n",
    "\n",
    "# start to predict the unconstant eggshell (prediciton, binary segmentation)\n",
    "if args.get_memb_bin:\n",
    "    # get membrane binary shell\n",
    "    # nii.gz to pickle, make it easier to read in neural network\n",
    "    # doit(test_folder, embryo_names=args.test_embryos, max_times=args.max_times)\n",
    "    # =============================================================\n",
    "    #  construct network model\n",
    "    # =============================================================\n",
    "    Network = getattr(models, args.net)\n",
    "    model = Network(**args.net_params)\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    print(\"=\"*20 + \"Loading parameters {}\".format(args.resume) + \"=\"*20)\n",
    "    assert os.path.isfile(args.resume), \"{} \".format(args.resume) + \"doesn't exist\"\n",
    "    check_point = torch.load(args.resume)\n",
    "    args.start_iter = check_point[\"iter\"]\n",
    "    model.load_state_dict(check_point[\"state_dict\"])\n",
    "\n",
    "    msg = (\"Loaded checkpoint '{}' (iter {})\".format(args.resume, check_point[\"iter\"]))\n",
    "    msg = msg + \"\\n\" + str(args)\n",
    "    \n",
    "#     logging.info(msg)\n",
    "    \n",
    "    root_path=args.running_data_dir\n",
    "    \n",
    "    if args.get_memb_bin or args.get_cell:\n",
    "        if args.running_embryos is None:\n",
    "            args.running_embryos = [name for name in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, name))]\n",
    "    Dataset = getattr(datasets, args.dataset)\n",
    "    test_set = Dataset(root=root_path, membrane_names=args.running_embryos, for_train=False, transforms=args.test_transforms,\n",
    "                       return_target=is_scoring, suffix=args.suffix, max_times=args.run_max_times)\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_set,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        # collate_fn=test_set.collate, # control how data is stacked\n",
    "        num_workers=10,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    #=============================================================\n",
    "    #  begin prediction\n",
    "    #=============================================================\n",
    "    output_saving_path=r'./dataset/run'\n",
    "\n",
    "    # the edt cell membrane file will save in the {savepath}/{embryo_name}/segMemb folder\n",
    "    with torch.no_grad():\n",
    "        validate(\n",
    "            valid_loader=test_loader,  # dataset loader\n",
    "            model=model,  # model\n",
    "            savepath=output_saving_path,  # output folder\n",
    "            names=test_set.names,  # stack name lists\n",
    "            scoring=False,  # whether keep accuracy\n",
    "            save_format=\".nii.gz\",  # save volume format\n",
    "            snapsot=visualizer,  # whether keep snap\n",
    "            postprocess=False,\n",
    "            size=test_set.size\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742cade",
   "metadata": {},
   "source": [
    "## From now on, you get the euclidean distance transformed cell membrane segmentation saved at ./dataset/run/{embryo_name}/SegMemb, which could be opened with ITK-SNAP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e3dbd",
   "metadata": {},
   "source": [
    "## Next, let's work on the cell object segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab05c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 12:03:35,752 Note: NumExpr detected 48 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-07-19 12:03:35,753 NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started  24  processes  <multiprocessing.pool.Pool state=RUN pool_size=24>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200109plc1p1 edt cell membrane --> single cell instance: 100%|█| 180/180 [2:30:18<00:00, 50.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started  24  processes  <multiprocessing.pool.Pool state=RUN pool_size=24>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200113plc1p2 edt cell membrane --> single cell instance: 100%|█| 187/187 [2:38:04<00:00, 50.72\n"
     ]
    }
   ],
   "source": [
    "from utils.prediction_utils import membrane2cell\n",
    "#  Post process on binary segmentation. Group them into closed 3D cells\n",
    "if args.get_cell:\n",
    "    # read the binary segmentation in segMemb folder and process them\n",
    "    membrane2cell(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3f011",
   "metadata": {},
   "source": [
    "## After we get the prespective dividing cells according to cell membrane segmentation results, we need to divide the wrong dividing cells into two cell regions with the cell object segmentation problem. So the speed may be slow while applying alpha shape generation in to dividing cells detecting (high memory costing so with only 1 cpu process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08158c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin combine division based on TP...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining the dividing cell in SegCellDividingCells) 200109plc1p1: 100%|█| 180/180 [46:04<00:0\n",
      "Combining the dividing cell in SegCellDividingCells) 200113plc1p2: 100%|██| 187/187 [43:46<00:00, 14.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from utils.prediction_utils import combine_dividing_cells\n",
    "if args.combine_dividing_cell:\n",
    "    #  Combine labels by detecting the dividing cells via the cell membrane segmentation\n",
    "    print(\"Begin combine division based on TP...\\n\")\n",
    "    combine_dividing_cells(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0f753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675f36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmap",
   "language": "python",
   "name": "cmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
